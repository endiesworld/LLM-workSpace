{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdacd322-3d3f-4532-9750-53607f131876",
   "metadata": {},
   "source": [
    "## Running an Elasticsearch cluster\n",
    "Uncomment the code below to run an Elasticsearch cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373d7351-b47a-48f2-b4d1-280ee9a50b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -d \\\n",
    "#     --name elasticsearch \\\n",
    "#     -m 4GB \\\n",
    "#     -p 9200:9200 \\\n",
    "#     -p 9300:9300 \\\n",
    "#     -e \"discovery.type=single-node\" \\\n",
    "#     -e \"xpack.security.enabled=false\" \\\n",
    "#     docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82567ca-2645-40e8-acea-72d19d9df179",
   "metadata": {},
   "source": [
    "### Next Step: Confirm with an API Ping\n",
    "To 100% confirm it's alive, run this in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c9d09b-b413-407f-8be0-54789f0916d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -X GET http://localhost:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a8690-48de-4e4e-81a3-9f2681e55a54",
   "metadata": {},
   "source": [
    "### Q1. Running Elastic-Result\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\" : \"1852f809dc58\",\n",
    "  \"cluster_name\" : \"docker-cluster\",\n",
    "  \"cluster_uuid\" : \"Zj0BSQXcS6CuWL28PaE0tA\",\n",
    "  \"version\" : {\n",
    "    \"number\" : \"8.4.3\",\n",
    "    \"build_flavor\" : \"default\",\n",
    "    \"build_type\" : \"docker\",\n",
    "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
    "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
    "    \"build_snapshot\" : false,\n",
    "    \"lucene_version\" : \"9.3.0\",\n",
    "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
    "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
    "  },\n",
    "  \"tagline\" : \"You Know, for Search\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4030435-a0a8-4c65-a884-b5991251e64f",
   "metadata": {},
   "source": [
    "**What's the version.build_hash value?:** 42f05b9372a9a4a470db3b52817899b99a76ee73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfd8909-6543-4614-8c85-2a6b0e55ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c039f0f-2a1c-405b-a4ed-51660b05c7f2",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "Now let's get the FAQ data. You can run this snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926035a0-192a-4ffd-9fdc-fbcef2f94470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd629c2-dc12-42b1-8a69-b665592830e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8594454-c696-4317-b392-7def0ba15171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a9a06d-74a0-4b9a-bfdc-c51e3afe2942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883bfbcf-15a5-47c3-889c-c58b057f40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'section', 'question', 'course'])\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c65600-d2d7-40f9-b76f-88bc08f30463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0874579c-539a-47ba-9231-7d7192ad525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
       " 'section': 'Module 6: Best practices',\n",
       " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
       " 'course': 'mlops-zoomcamp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade3622-378a-45c6-97c9-1b9949280a9c",
   "metadata": {},
   "source": [
    "## Q2. Indexing the data\n",
    "Index the data in the same way as was shown in the course videos. Make the course field a keyword and the rest should be text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116e4281-b1e8-4fbe-8c00-483f13165404",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://172.17.0.1:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e351ea-b16b-4acc-ad25-db0325c421ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'bdbc40c79ada', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'Zifa-ednRKWqZDb0XaFfFQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92eb75ac-c950-4183-b6fd-0728b270567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\n",
    "                    \"keyword\": { \"type\": \"keyword\" }\n",
    "                }\n",
    "            },\n",
    "            \"section\": { \"type\": \"text\" },\n",
    "            \"question\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\n",
    "                    \"keyword\": { \"type\": \"keyword\" }\n",
    "                }\n",
    "            },\n",
    "            \"course\": { \"type\": \"keyword\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "922461c3-7024-405e-a391-0ab355eb6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814f2d01-a415-46b8-ba16-bc3672be1067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89755f9f3f54fd8bca6afbaade47479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfca205-46fa-46f8-8858-0e31ca97be4a",
   "metadata": {},
   "source": [
    "**Which function do you use for adding your data to elastic?** <br>\n",
    "**Answer:** index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7796a-2cb5-40f5-9965-1b9ca36c09e2",
   "metadata": {},
   "source": [
    "### Q3. Searching\n",
    "Now let's search in our index.<br>\n",
    "We will execute a query \"How do execute a command on a Kubernetes pod?\".<br>\n",
    "Use only question and text fields and give question a boost of 4, and use \"type\": \"best_fields\".<br>\n",
    "\n",
    "What's the score for the top ranking result?<br>\n",
    "\n",
    "- 84.50\n",
    "- 64.50\n",
    "- 44.50\n",
    "- 24.50<br>\n",
    "Look at the _score field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9631e31-5f1d-416f-ace0-b79316d72efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question\n",
    "query = 'How do execute a command on a Kubernetes pod?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c03703-7240-404c-87ca-b8abb2ad237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_top_score(query, filter=None, results=1):\n",
    "    search_query = {\n",
    "        \"size\": results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": filter\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit)\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "523dd0bd-8bf0-45db-b705-2763eb3d5843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': 'HAWXZJcBm_zZyQBYRqOL',\n",
       "  '_score': 44.50556,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search_top_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21055bec-51f7-4871-8717-2e2440421dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the top ranking result is:  44.50556\n"
     ]
    }
   ],
   "source": [
    "print(\"The score of the top ranking result is: \", elastic_search_top_score(query)[0]['_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f648c76-0d14-405b-b55a-870f3ffcecf1",
   "metadata": {},
   "source": [
    "### Q4. Filtering\n",
    "Now ask a different question: \"How do copy a file to a Docker container?\".<br>\n",
    "\n",
    "This time we are only interested in questions from machine-learning-zoomcamp.<br>\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?<br>\n",
    "\n",
    "- How do I debug a docker container?\n",
    "- How do I copy files from a different folder into docker container’s working directory?<br>\n",
    "- How do Lambda container images work?<br>\n",
    "- How can I annotate a graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8942b95b-6d13-408b-8654-b5a8ac1da909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the 3rd question returned by the search engine?\n",
      "Answer:  How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: What's the 3rd question returned by the search engine?\")\n",
    "\n",
    "filter = {\n",
    "    \"term\": {\n",
    "                \"course\": \"machine-learning-zoomcamp\"\n",
    "            }\n",
    "}\n",
    "resul_size = 3\n",
    "query = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "print(\"Answer: \", elastic_search_top_score(query, filter, resul_size )[2]['_source']['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7295cff-d347-47fd-943d-ebe937f6a9af",
   "metadata": {},
   "source": [
    "### Question: What's the 3rd question returned by the search engine?\n",
    "**Answer:**  How do I copy files from a different folder into docker container’s working directory?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f502ce7-83fc-4fe8-a024-75dee4240e39",
   "metadata": {},
   "source": [
    "### Q5. Building a prompt\n",
    "Now we're ready to build a prompt to send to an LLM.\n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (\\n\\n)\n",
    "\n",
    "```python\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "Now use the context you just created along with the \"How do copy a file to a Docker container?\" question to construct a prompt using the template below:\n",
    "\n",
    "```python\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e4f8043-a6b1-4639-8367-9ad003f2ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e920cc7f-61bb-4984-886d-c2bad0f32133",
   "metadata": {},
   "source": [
    "***What's the length of the resulting prompt? (use the len function)***\n",
    "- 946\n",
    "- 1446\n",
    "- 1946\n",
    "- 2446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6015ca7b-45ea-4def-a1d8-e94522f2fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the prompt is:  1447\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "results = elastic_search_top_score(query, filter, resul_size )\n",
    "for record in results:\n",
    "    records.append(record['_source'])\n",
    "\n",
    "prompt = build_prompt(query, records)\n",
    "print(\"The length of the prompt is: \", len(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79dc7f9-f25f-4c56-9abe-65f8530b9992",
   "metadata": {},
   "source": [
    "### Question: What's the length of the resulting prompt? (use the len function)\n",
    "**Answer:** 1446"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e1e7b-d364-4c1b-9a24-ec8dc15dac25",
   "metadata": {},
   "source": [
    "## Q6. Tokens\n",
    "When we use the OpenAI Platform, we're charged by the number of tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses tiktoken for tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6682249-a8eb-4b46-af21-b3c6ed57a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tiktoken]\n",
      "\u001b[1A\u001b[2KSuccessfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a400d475-9984-479b-bf3a-e287c13143b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 321\n",
      "Token IDs: [63842, 261, 4165, 14029, 29186, 13, 30985, 290, 150339, 4122, 402, 290, 31810, 8099, 591, 290, 40251, 7862, 558, 8470, 1606, 290, 19719, 591, 290, 31810, 8099, 1261, 55959, 290, 150339, 364, 107036, 25, 3253, 621, 5150, 261, 1974, 316, 261, 91238, 9282, 1715, 10637, 50738, 25, 793, 48, 25, 3253, 621, 357, 15199, 261, 62275, 9282, 3901, 32, 25, 41281, 290, 9282, 3621, 306, 25383, 6766, 326, 151187, 290, 7251, 4859, 11, 813, 484, 480, 13217, 261, 38615, 6348, 558, 68923, 2461, 533, 278, 2230, 7962, 4859, 38615, 464, 3365, 523, 3335, 290, 9282, 382, 4279, 6788, 11, 15792, 261, 6348, 306, 290, 4857, 9282, 734, 68923, 10942, 350, 6555, 290, 9282, 26240, 446, 68923, 25398, 533, 278, 464, 6896, 26240, 29, 38615, 198, 6103, 277, 10732, 391, 79771, 1029, 48, 25, 3253, 621, 357, 5150, 6291, 591, 922, 2698, 7342, 316, 62275, 9282, 3901, 32, 25, 1608, 665, 5150, 6291, 591, 634, 2698, 7342, 1511, 261, 91238, 9282, 2360, 290, 62275, 27776, 6348, 13, 44257, 1495, 316, 621, 480, 734, 1385, 5150, 261, 1974, 503, 12552, 591, 634, 2698, 7342, 1511, 261, 6788, 91238, 9282, 11, 481, 665, 1199, 290, 2700, 68923, 27776, 6348, 62102, 623, 9439, 45440, 382, 472, 18183, 734, 68923, 27776, 820, 4189, 72231, 52214, 51766, 15400, 35850, 9282, 1537, 27975, 4189, 26985, 190543, 198, 106096, 437, 507, 70737, 15241, 3048, 279, 48, 25, 3253, 621, 357, 5150, 6291, 591, 261, 2647, 15610, 1511, 62275, 9282, 802, 4113, 12552, 3901, 32, 25, 1608, 665, 5150, 6291, 591, 634, 2698, 7342, 1511, 261, 91238, 9282, 2360, 290, 62275, 27776, 6348, 13, 44257, 1495, 316, 621, 480, 734, 637, 290, 91238, 2318, 11, 481, 665, 3587, 290, 15610, 15683, 290, 6291, 484, 481, 1682, 316, 5150, 1072, 13, 623, 9439, 45440, 382, 472, 18183, 734, 128701, 9129, 7205, 8138, 21369, 17311, 672, 392, 13123, 22739, 9320, 10928, 69422, 672, 9633, 2601, 14973, 22713, 167296, 30463, 499, 137058, 22064]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load tokenizer for GPT-4\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "tokens = enc.encode(prompt)\n",
    "\n",
    "print(\"Token count:\", len(tokens))\n",
    "print(\"Token IDs:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdea111-4259-43ff-9567-336677dcfbfb",
   "metadata": {},
   "source": [
    "### Use the encode function. How many tokens does our prompt have?\n",
    "**Answer:** 320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40087d9-75a1-484e-9ea9-3e296e5490b8",
   "metadata": {},
   "source": [
    "## Bonus: generating the answer (ungraded)\n",
    "Let's send the prompt to OpenAI. What's the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "869cf1ae-9c79-421b-85f0-0594ea957d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, client):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65fbec65-1261-4f10-9bd9-f6693706952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_openAI(prompt):\n",
    "    client = OpenAI()\n",
    "    answer = llm(prompt, client)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5b625a3-e318-4f58-b2a9-bb9a537b5cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To copy a file from your local machine into a Docker container, you can use the `docker cp` command. The basic syntax is:\\n\\n```\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\n```\\n\\nThis command allows you to specify the path to the file or directory on your local machine, the ID of the container, and the path within the container where you want the file to be copied.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_openAI(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0d2fb-08fe-48e4-a7be-d24cf0ab589a",
   "metadata": {},
   "source": [
    "## Bonus: calculating the costs (ungraded)\n",
    "Suppose that on average per request we send 150 tokens and receive back 250 tokens.\n",
    "\n",
    "How much will it cost to run 1000 requests?\n",
    "\n",
    "On June 17, the prices for gpt4o are:\n",
    "- Input: $0.005 / 1K tokens\n",
    "\n",
    "- Output: $0.015 / 1K tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1072bcb2-72bb-4edd-b84b-70d366c493db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price for 150000 input token is:  0.75\n",
      "Price for 250000 input token is:  3.75\n"
     ]
    }
   ],
   "source": [
    "avg_input_token = 150\n",
    "avg_output_token = 250\n",
    "requests = 1000\n",
    "\n",
    "input_token = avg_input_token * requests\n",
    "output_token = avg_output_token * requests\n",
    "\n",
    "price_per_input_token = 0.005 / 1000\n",
    "price_per_output_token = 0.015 / 1000\n",
    "\n",
    "print(f\"Price for {input_token} input token is: \", round(input_token* price_per_input_token, 2))\n",
    "print(f\"Price for {output_token} input token is: \", round(output_token* price_per_output_token, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe485c9-12bb-41fb-a2ea-afa203229731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
